{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Anscombe Transform","text":"<p>Zarr V2 and V3 codecs for compressing photon-limited movies using the Anscombe Transform.</p>"},{"location":"#what-is-it","title":"What is it?","text":"<p>This codec is designed for compressing movies with Poisson noise, which are produced by photon-limited modalities such as:</p> <ul> <li>Multiphoton microscopy</li> <li>Radiography</li> <li>Astronomy</li> </ul>"},{"location":"#how-it-works","title":"How it works","text":"<p>The codec re-quantizes grayscale data efficiently using a square-root-like transformation to equalize noise variance across grayscale levels: the Anscombe Transform. This results in:</p> <ul> <li>Fewer unique grayscale levels</li> <li>Significant improvements in data compressibility</li> <li>No sacrifice to signal accuracy</li> </ul>"},{"location":"#requirements","title":"Requirements","text":"<p>To use the codec, you need to provide two pieces of information:</p> <ol> <li><code>zero_level</code>: The input value corresponding to the absence of light</li> <li><code>conversion_gain</code> (also called <code>photon_sensitivity</code>): The conversion factor from signal levels to photon counts</li> </ol> <p>The codec assumes that the video is linearly encoded with a potential offset and that these parameters can be accurately estimated from the data.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>\u2705 Zarr V2 support via <code>numcodecs</code> interface</li> <li>\u2705 Zarr V3 support via <code>ArrayArrayCodec</code> interface</li> <li>\u2705 Automatic parameter estimation from data</li> <li>\u2705 Lossless compression for photon-limited data</li> <li>\u2705 Python 3.11+ support</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>import zarr\nimport numpy as np\nfrom anscombe_transform import AnscombeTransformV3\n\n# Create sample data with Poisson noise\ndata = np.random.poisson(lam=50, size=(100, 512, 512)).astype('int16')\n\n# Create Zarr array with Anscombe codec\nstore = zarr.storage.MemoryStore()\narr = zarr.create(\n    store=store,\n    shape=data.shape,\n    chunks=(10, 512, 512),\n    dtype='int16',\n    filters=[AnscombeTransformV3(zero_level=100, conversion_gain=2.5)],\n    zarr_format=3\n)\n\n# Write and read data\narr[:] = data\nrecovered = arr[:]\n</code></pre>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Installation Guide</li> <li>Quick Start Tutorial</li> <li>User Guide</li> <li>API Reference</li> </ul>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#development-setup","title":"Development Setup","text":""},{"location":"contributing/#getting-started","title":"Getting Started","text":"<ol> <li>Fork and clone the repository</li> </ol> <pre><code>git clone https://github.com/YOUR_USERNAME/anscombe-transform.git\ncd anscombe-transform\n</code></pre> <ol> <li>Install Hatch</li> </ol> <p>Via pip:</p> <pre><code>pip install hatch\n</code></pre> <p>Or directly.</p> <ol> <li>Create a development environment</li> </ol> <pre><code># See available environments\nhatch env show\n\n# Enter a test environment\nhatch shell test.py3.11-2.2\n</code></pre> <ol> <li>Run tests</li> </ol> <pre><code># Run all tests\nhatch run test:pytest tests/\n\n# Run specific test file\nhatch run test:pytest tests/test_codec.py\n\n# Run with coverage\nhatch run test:pytest tests/ --cov=src/anscombe_transform\n</code></pre>"},{"location":"contributing/#testing","title":"Testing","text":"<p>The project uses pytest for testing. Tests are organized in the <code>tests/</code> directory.</p>"},{"location":"contributing/#building-documentation","title":"Building Documentation","text":""},{"location":"contributing/#local-documentation-server","title":"Local Documentation Server","text":"<pre><code># Install docs dependencies\nhatch run docs:mkdocs serve\n\n# View at http://127.0.0.1:8000\n</code></pre>"},{"location":"contributing/#building-documentation_1","title":"Building Documentation","text":"<pre><code># Build static site\nhatch run docs:mkdocs build\n\n# Output in site/\n</code></pre>"},{"location":"contributing/#getting-help","title":"Getting Help","text":"<ul> <li>Questions? Open a GitHub Discussion</li> <li>Bug reports? Open an Issue</li> </ul>"},{"location":"contributing/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the MIT License.</p>"},{"location":"api/codec/","title":"Codec API Reference","text":"<p>This page documents the codec implementations for both Zarr V2 and V3.</p>"},{"location":"api/codec/#anscombetransformv3","title":"AnscombeTransformV3","text":""},{"location":"api/codec/#anscombe_transform.codec.AnscombeTransformV3","title":"<code>AnscombeTransformV3</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ArrayArrayCodec</code></p> <p>Zarr v3 codec for Anscombe Transform for photon-limited data.</p> <p>The codec assumes input data has linear encoding with Poisson noise, typically from photon-limited imaging modalities.</p> <p>Attributes:</p> Name Type Description <code>zero_level</code> <code>int</code> <p>Signal level when no photons are recorded.</p> <code>conversion_gain</code> <code>float</code> <p>Signal intensity increase per photon.</p> <code>encoded_dtype</code> <code>str</code> <p>Data type for encoded values (default: \"uint8\").</p> <code>decoded_dtype</code> <code>str</code> <p>Data type for decoded values (default: \"int16\").</p> <code>is_fixed_size</code> <code>bool</code> <p>Whether the codec produces fixed-size output (default: True).</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>@dataclass(frozen=True, slots=True)\nclass AnscombeTransformV3(ArrayArrayCodec):\n    \"\"\"\n    Zarr v3 codec for Anscombe Transform for photon-limited data.\n\n    The codec assumes input data has linear encoding with Poisson noise,\n    typically from photon-limited imaging modalities.\n\n    Attributes\n    ----------\n    zero_level : int\n        Signal level when no photons are recorded.\n    conversion_gain : float\n        Signal intensity increase per photon.\n    encoded_dtype : str\n        Data type for encoded values (default: \"uint8\").\n    decoded_dtype : str\n        Data type for decoded values (default: \"int16\").\n    is_fixed_size : bool\n        Whether the codec produces fixed-size output (default: True).\n    \"\"\"\n\n    zero_level: int\n    conversion_gain: float\n    encoded_dtype: str = \"uint8\"\n    decoded_dtype: str = \"int16\"\n    is_fixed_size: bool = True\n\n    @classmethod\n    def from_dict(cls, data: dict) -&gt; Self:\n        \"\"\"\n        Create codec instance from configuration dictionary.\n\n        Parameters\n        ----------\n        data : dict\n            Configuration dictionary with 'configuration' key containing codec parameters.\n\n        Returns\n        -------\n        AnscombeTransformV3\n            New codec instance.\n        \"\"\"\n        config = data.get(\"configuration\", {})\n        return cls(\n            zero_level=config[\"zero_level\"],\n            conversion_gain=config[\"conversion_gain\"],\n            encoded_dtype=config.get(\"encoded_dtype\", \"uint8\"),\n            decoded_dtype=config.get(\"decoded_dtype\", \"int16\"),\n        )\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"\n        Convert codec to configuration dictionary.\n\n        Returns\n        -------\n        dict\n            Configuration dictionary with codec name and parameters.\n        \"\"\"\n        return {\n            \"name\": \"anscombe-v1\",\n            \"configuration\": {\n                \"zero_level\": self.zero_level,\n                \"conversion_gain\": self.conversion_gain,\n                \"encoded_dtype\": self.encoded_dtype,\n                \"decoded_dtype\": self.decoded_dtype,\n            },\n        }\n\n    def resolve_metadata(self, chunk_spec: ArraySpec) -&gt; ArraySpec:\n        \"\"\"\n        Resolve metadata for encoded output.\n\n        Parameters\n        ----------\n        chunk_spec : ArraySpec\n            Input chunk specification.\n\n        Returns\n        -------\n        ArraySpec\n            Output chunk specification with updated dtype.\n        \"\"\"\n        return ArraySpec(\n            shape=chunk_spec.shape,\n            dtype=parse_dtype(np.dtype(self.encoded_dtype), zarr_format=3),\n            fill_value=chunk_spec.fill_value,\n            config=chunk_spec.config,\n            prototype=chunk_spec.prototype,\n        )\n\n    def _encode(self, buf: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Encode data synchronously for direct use.\n\n        Parameters\n        ----------\n        buf : np.ndarray\n            Input array to encode.\n\n        Returns\n        -------\n        np.ndarray\n            Encoded array.\n        \"\"\"\n        return encode(\n            buf,\n            conversion_gain=self.conversion_gain,\n            zero_level=self.zero_level,\n            encoded_dtype=self.encoded_dtype,\n        )\n\n    def _decode(self, buf: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Decode data synchronously for direct use.\n\n        Parameters\n        ----------\n        buf : np.ndarray\n            Encoded buffer to decode.\n\n        Returns\n        -------\n        np.ndarray\n            Decoded array.\n        \"\"\"\n        return decode(\n            buf.tobytes(),\n            conversion_gain=self.conversion_gain,\n            zero_level=self.zero_level,\n            encoded_dtype=self.encoded_dtype,\n            decoded_dtype=self.decoded_dtype,\n        )\n\n    async def _encode_single(\n        self,\n        chunk_array,\n        chunk_spec,\n    ):\n        \"\"\"\n        Encode a single chunk using Anscombe transform.\n\n        Parameters\n        ----------\n        chunk_array : NDBuffer\n            Input chunk to encode.\n        chunk_spec : ArraySpec\n            Chunk specification.\n\n        Returns\n        -------\n        NDBuffer\n            Encoded chunk.\n        \"\"\"\n        # Convert NDBuffer to numpy array\n        data = chunk_array.as_numpy_array()\n\n        # Apply encoding\n        encoded = self._encode(data)\n\n        # Return as NDBuffer\n        return chunk_array.from_numpy_array(encoded)\n\n    async def _decode_single(\n        self,\n        chunk_array,\n        chunk_spec,\n    ):\n        \"\"\"\n        Decode a single chunk using inverse Anscombe transform.\n\n        Parameters\n        ----------\n        chunk_array : NDBuffer\n            Encoded chunk to decode.\n        chunk_spec : ArraySpec\n            Chunk specification.\n\n        Returns\n        -------\n        NDBuffer\n            Decoded chunk.\n        \"\"\"\n        # Convert NDBuffer to numpy array\n        data = chunk_array.as_numpy_array()\n\n        # Apply decoding\n        decoded = self._decode(data)\n\n        # Reshape to original shape\n        decoded = decoded.reshape(chunk_spec.shape)\n\n        # Return as NDBuffer\n        return chunk_array.from_numpy_array(decoded)\n</code></pre>"},{"location":"api/codec/#anscombe_transform.codec.AnscombeTransformV3.from_dict","title":"<code>from_dict(data)</code>  <code>classmethod</code>","text":"<p>Create codec instance from configuration dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Configuration dictionary with 'configuration' key containing codec parameters.</p> required <p>Returns:</p> Type Description <code>AnscombeTransformV3</code> <p>New codec instance.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict) -&gt; Self:\n    \"\"\"\n    Create codec instance from configuration dictionary.\n\n    Parameters\n    ----------\n    data : dict\n        Configuration dictionary with 'configuration' key containing codec parameters.\n\n    Returns\n    -------\n    AnscombeTransformV3\n        New codec instance.\n    \"\"\"\n    config = data.get(\"configuration\", {})\n    return cls(\n        zero_level=config[\"zero_level\"],\n        conversion_gain=config[\"conversion_gain\"],\n        encoded_dtype=config.get(\"encoded_dtype\", \"uint8\"),\n        decoded_dtype=config.get(\"decoded_dtype\", \"int16\"),\n    )\n</code></pre>"},{"location":"api/codec/#anscombe_transform.codec.AnscombeTransformV3.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert codec to configuration dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Configuration dictionary with codec name and parameters.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"\n    Convert codec to configuration dictionary.\n\n    Returns\n    -------\n    dict\n        Configuration dictionary with codec name and parameters.\n    \"\"\"\n    return {\n        \"name\": \"anscombe-v1\",\n        \"configuration\": {\n            \"zero_level\": self.zero_level,\n            \"conversion_gain\": self.conversion_gain,\n            \"encoded_dtype\": self.encoded_dtype,\n            \"decoded_dtype\": self.decoded_dtype,\n        },\n    }\n</code></pre>"},{"location":"api/codec/#anscombe_transform.codec.AnscombeTransformV3.resolve_metadata","title":"<code>resolve_metadata(chunk_spec)</code>","text":"<p>Resolve metadata for encoded output.</p> <p>Parameters:</p> Name Type Description Default <code>chunk_spec</code> <code>ArraySpec</code> <p>Input chunk specification.</p> required <p>Returns:</p> Type Description <code>ArraySpec</code> <p>Output chunk specification with updated dtype.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>def resolve_metadata(self, chunk_spec: ArraySpec) -&gt; ArraySpec:\n    \"\"\"\n    Resolve metadata for encoded output.\n\n    Parameters\n    ----------\n    chunk_spec : ArraySpec\n        Input chunk specification.\n\n    Returns\n    -------\n    ArraySpec\n        Output chunk specification with updated dtype.\n    \"\"\"\n    return ArraySpec(\n        shape=chunk_spec.shape,\n        dtype=parse_dtype(np.dtype(self.encoded_dtype), zarr_format=3),\n        fill_value=chunk_spec.fill_value,\n        config=chunk_spec.config,\n        prototype=chunk_spec.prototype,\n    )\n</code></pre>"},{"location":"api/codec/#anscombetransformv2","title":"AnscombeTransformV2","text":""},{"location":"api/codec/#anscombe_transform.codec.AnscombeTransformV2","title":"<code>AnscombeTransformV2</code>  <code>dataclass</code>","text":"<p>Zarr v2 codec for Anscombe Transform for photon-limited data.</p> <p>The codec assumes input data has linear encoding with Poisson noise, typically from photon-limited imaging modalities.</p> <p>Attributes:</p> Name Type Description <code>codec_id</code> <code>str</code> <p>Codec identifier (\"anscombe-v1\").</p> <code>zero_level</code> <code>int</code> <p>Signal level when no photons are recorded.</p> <code>conversion_gain</code> <code>float</code> <p>Signal intensity increase per photon.</p> <code>encoded_dtype</code> <code>str</code> <p>Data type for encoded values (default: \"uint8\").</p> <code>decoded_dtype</code> <code>str</code> <p>Data type for decoded values (default: \"int16\").</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>@dataclass(frozen=True, slots=True)\nclass AnscombeTransformV2:\n    \"\"\"\n    Zarr v2 codec for Anscombe Transform for photon-limited data.\n\n    The codec assumes input data has linear encoding with Poisson noise,\n    typically from photon-limited imaging modalities.\n\n    Attributes\n    ----------\n    codec_id : str\n        Codec identifier (\"anscombe-v1\").\n    zero_level : int\n        Signal level when no photons are recorded.\n    conversion_gain : float\n        Signal intensity increase per photon.\n    encoded_dtype : str\n        Data type for encoded values (default: \"uint8\").\n    decoded_dtype : str\n        Data type for decoded values (default: \"int16\").\n    \"\"\"\n\n    codec_id: ClassVar[Literal[\"anscombe-v1\"]] = \"anscombe-v1\"\n    zero_level: int\n    conversion_gain: float\n    encoded_dtype: str = \"uint8\"\n    decoded_dtype: str = \"int16\"\n\n    def encode(self, buf: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Encode data using Anscombe transform.\n\n        Parameters\n        ----------\n        buf : np.ndarray\n            Input array to encode.\n\n        Returns\n        -------\n        np.ndarray\n            Encoded array.\n        \"\"\"\n        return encode(\n            buf,\n            conversion_gain=self.conversion_gain,\n            zero_level=self.zero_level,\n            encoded_dtype=self.encoded_dtype,\n        )\n\n    def decode(self, buf: bytes, out: object | None = None) -&gt; np.ndarray:\n        \"\"\"\n        Decode data using inverse Anscombe transform.\n\n        Parameters\n        ----------\n        buf : bytes\n            Encoded buffer to decode.\n        out : object or None, optional\n            Output buffer (unused), by default None.\n\n        Returns\n        -------\n        np.ndarray\n            Decoded array.\n        \"\"\"\n        return decode(\n            buf,\n            conversion_gain=self.conversion_gain,\n            zero_level=self.zero_level,\n            encoded_dtype=self.encoded_dtype,\n            decoded_dtype=self.decoded_dtype,\n        )\n\n    def get_config(self) -&gt; AnscomeCodecJSON_V2:\n        \"\"\"\n        Get codec configuration dictionary.\n\n        Returns\n        -------\n        dict\n            Configuration dictionary with codec ID and parameters.\n        \"\"\"\n        return {\n            \"id\": self.codec_id,\n            \"zero_level\": self.zero_level,\n            \"conversion_gain\": self.conversion_gain,\n        }\n\n    @classmethod\n    def from_config(cls, config: AnscomeCodecJSON_V2) -&gt; Self:\n        \"\"\"\n        Create codec instance from configuration dictionary.\n\n        Parameters\n        ----------\n        config : dict\n            Configuration dictionary with 'zero_level' and 'conversion_gain' keys.\n\n        Returns\n        -------\n        AnscombeTransformV2\n            New codec instance.\n        \"\"\"\n        return cls(zero_level=config[\"zero_level\"], conversion_gain=config[\"conversion_gain\"])\n</code></pre>"},{"location":"api/codec/#anscombe_transform.codec.AnscombeTransformV2.encode","title":"<code>encode(buf)</code>","text":"<p>Encode data using Anscombe transform.</p> <p>Parameters:</p> Name Type Description Default <code>buf</code> <code>ndarray</code> <p>Input array to encode.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Encoded array.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>def encode(self, buf: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Encode data using Anscombe transform.\n\n    Parameters\n    ----------\n    buf : np.ndarray\n        Input array to encode.\n\n    Returns\n    -------\n    np.ndarray\n        Encoded array.\n    \"\"\"\n    return encode(\n        buf,\n        conversion_gain=self.conversion_gain,\n        zero_level=self.zero_level,\n        encoded_dtype=self.encoded_dtype,\n    )\n</code></pre>"},{"location":"api/codec/#anscombe_transform.codec.AnscombeTransformV2.decode","title":"<code>decode(buf, out=None)</code>","text":"<p>Decode data using inverse Anscombe transform.</p> <p>Parameters:</p> Name Type Description Default <code>buf</code> <code>bytes</code> <p>Encoded buffer to decode.</p> required <code>out</code> <code>object or None</code> <p>Output buffer (unused), by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Decoded array.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>def decode(self, buf: bytes, out: object | None = None) -&gt; np.ndarray:\n    \"\"\"\n    Decode data using inverse Anscombe transform.\n\n    Parameters\n    ----------\n    buf : bytes\n        Encoded buffer to decode.\n    out : object or None, optional\n        Output buffer (unused), by default None.\n\n    Returns\n    -------\n    np.ndarray\n        Decoded array.\n    \"\"\"\n    return decode(\n        buf,\n        conversion_gain=self.conversion_gain,\n        zero_level=self.zero_level,\n        encoded_dtype=self.encoded_dtype,\n        decoded_dtype=self.decoded_dtype,\n    )\n</code></pre>"},{"location":"api/codec/#anscombe_transform.codec.AnscombeTransformV2.get_config","title":"<code>get_config()</code>","text":"<p>Get codec configuration dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Configuration dictionary with codec ID and parameters.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>def get_config(self) -&gt; AnscomeCodecJSON_V2:\n    \"\"\"\n    Get codec configuration dictionary.\n\n    Returns\n    -------\n    dict\n        Configuration dictionary with codec ID and parameters.\n    \"\"\"\n    return {\n        \"id\": self.codec_id,\n        \"zero_level\": self.zero_level,\n        \"conversion_gain\": self.conversion_gain,\n    }\n</code></pre>"},{"location":"api/codec/#anscombe_transform.codec.AnscombeTransformV2.from_config","title":"<code>from_config(config)</code>  <code>classmethod</code>","text":"<p>Create codec instance from configuration dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Configuration dictionary with 'zero_level' and 'conversion_gain' keys.</p> required <p>Returns:</p> Type Description <code>AnscombeTransformV2</code> <p>New codec instance.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>@classmethod\ndef from_config(cls, config: AnscomeCodecJSON_V2) -&gt; Self:\n    \"\"\"\n    Create codec instance from configuration dictionary.\n\n    Parameters\n    ----------\n    config : dict\n        Configuration dictionary with 'zero_level' and 'conversion_gain' keys.\n\n    Returns\n    -------\n    AnscombeTransformV2\n        New codec instance.\n    \"\"\"\n    return cls(zero_level=config[\"zero_level\"], conversion_gain=config[\"conversion_gain\"])\n</code></pre>"},{"location":"api/codec/#core-functions","title":"Core Functions","text":""},{"location":"api/codec/#encode","title":"encode","text":""},{"location":"api/codec/#anscombe_transform.codec.encode","title":"<code>encode(buf, *, conversion_gain, zero_level, encoded_dtype)</code>","text":"<p>Encode an array using the Anscombe transform.</p> <p>Parameters:</p> Name Type Description Default <code>buf</code> <code>ndarray</code> <p>Input array to encode.</p> required <code>conversion_gain</code> <code>float</code> <p>Signal intensity increase per photon.</p> required <code>zero_level</code> <code>int</code> <p>Signal level when no photons are recorded.</p> required <code>encoded_dtype</code> <code>str</code> <p>NumPy dtype string for encoded output.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Encoded array with variance-stabilized values.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>def encode(\n    buf: np.ndarray, *, conversion_gain: float, zero_level: int, encoded_dtype: str\n) -&gt; np.ndarray:\n    \"\"\"\n    Encode an array using the Anscombe transform.\n\n    Parameters\n    ----------\n    buf : np.ndarray\n        Input array to encode.\n    conversion_gain : float\n        Signal intensity increase per photon.\n    zero_level : int\n        Signal level when no photons are recorded.\n    encoded_dtype : str\n        NumPy dtype string for encoded output.\n\n    Returns\n    -------\n    np.ndarray\n        Encoded array with variance-stabilized values.\n    \"\"\"\n    lut = make_anscombe_lookup(\n        conversion_gain,\n        output_type=encoded_dtype,\n        zero_level=zero_level,\n    )\n    encoded = lookup(buf, lut)\n    return encoded.astype(encoded_dtype)\n</code></pre>"},{"location":"api/codec/#decode","title":"decode","text":""},{"location":"api/codec/#anscombe_transform.codec.decode","title":"<code>decode(buf, *, conversion_gain, zero_level, encoded_dtype, decoded_dtype)</code>","text":"<p>Decode an array using the inverse Anscombe transform.</p> <p>Parameters:</p> Name Type Description Default <code>buf</code> <code>bytes or ndarray</code> <p>Encoded buffer to decode.</p> required <code>conversion_gain</code> <code>float</code> <p>Signal intensity increase per photon.</p> required <code>zero_level</code> <code>int</code> <p>Signal level when no photons are recorded.</p> required <code>encoded_dtype</code> <code>DtypeLike</code> <p>NumPy dtype of encoded data.</p> required <code>decoded_dtype</code> <code>DtypeLike</code> <p>NumPy dtype for decoded output.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Decoded array with original value scale.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>def decode(\n    buf: bytes | np.ndarray,\n    *,\n    conversion_gain: float,\n    zero_level: int,\n    encoded_dtype: npt.DtypeLike,\n    decoded_dtype: npt.DTypeLike,\n) -&gt; np.ndarray:\n    \"\"\"\n    Decode an array using the inverse Anscombe transform.\n\n    Parameters\n    ----------\n    buf : bytes or np.ndarray\n        Encoded buffer to decode.\n    conversion_gain : float\n        Signal intensity increase per photon.\n    zero_level : int\n        Signal level when no photons are recorded.\n    encoded_dtype : numpy.typing.DtypeLike\n        NumPy dtype of encoded data.\n    decoded_dtype : numpy.typing.DtypeLike\n        NumPy dtype for decoded output.\n\n    Returns\n    -------\n    np.ndarray\n        Decoded array with original value scale.\n    \"\"\"\n    lookup_table = make_anscombe_lookup(\n        conversion_gain,\n        output_type=encoded_dtype,\n        zero_level=zero_level,\n    )\n    inverse_table = make_inverse_lookup(lookup_table, output_type=decoded_dtype)\n    decoded = np.frombuffer(buf, dtype=encoded_dtype)\n    return lookup(decoded, inverse_table).astype(decoded_dtype)\n</code></pre>"},{"location":"api/codec/#lookup-table-functions","title":"Lookup Table Functions","text":""},{"location":"api/codec/#make_anscombe_lookup","title":"make_anscombe_lookup","text":""},{"location":"api/codec/#anscombe_transform.codec.make_anscombe_lookup","title":"<code>make_anscombe_lookup(conversion_gain, input_max=32767, zero_level=0, beta=0.5, output_type='uint8')</code>","text":"<p>Compute the Anscombe lookup table.</p> <p>The lookup converts a linear grayscale image into a uniform variance image by applying the Anscombe variance-stabilizing transformation.</p> <p>Parameters:</p> Name Type Description Default <code>conversion_gain</code> <code>float</code> <p>Estimated signal intensity increase per quantum (e.g. photon).</p> required <code>input_max</code> <code>int</code> <p>The maximum value in the input data, by default 0x7FFF (32767).</p> <code>32767</code> <code>zero_level</code> <code>int</code> <p>Signal level when no photons are recorded, by default 0.</p> <code>0</code> <code>beta</code> <code>float</code> <p>The grayscale quantization step expressed in units of noise std dev, by default 0.5.</p> <code>0.5</code> <code>output_type</code> <code>str</code> <p>NumPy dtype string for output array, by default \"uint8\".</p> <code>'uint8'</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Lookup table array for Anscombe transformation.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>def make_anscombe_lookup(\n    conversion_gain: float,\n    input_max: int = 0x7FFF,\n    zero_level: int = 0,\n    beta: float = 0.5,\n    output_type: str = \"uint8\",\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute the Anscombe lookup table.\n\n    The lookup converts a linear grayscale image into a uniform variance image\n    by applying the Anscombe variance-stabilizing transformation.\n\n    Parameters\n    ----------\n    conversion_gain : float\n        Estimated signal intensity increase per quantum (e.g. photon).\n    input_max : int, optional\n        The maximum value in the input data, by default 0x7FFF (32767).\n    zero_level : int, optional\n        Signal level when no photons are recorded, by default 0.\n    beta : float, optional\n        The grayscale quantization step expressed in units of noise std dev, by default 0.5.\n    output_type : str, optional\n        NumPy dtype string for output array, by default \"uint8\".\n\n    Returns\n    -------\n    np.ndarray\n        Lookup table array for Anscombe transformation.\n    \"\"\"\n    xx = (np.r_[: input_max + 1] - zero_level) / conversion_gain  # input expressed in photon rates\n    zero_slope = 1 / beta / np.sqrt(3 / 8)  # slope for negative values\n    offset = zero_level * zero_slope / conversion_gain\n    lookup_table = np.round(\n        offset\n        + (xx &lt; 0) * (xx * zero_slope)\n        + (xx &gt;= 0) * (2.0 / beta * (np.sqrt(np.maximum(0, xx) + 3 / 8) - np.sqrt(3 / 8)))\n    )\n    lookup = lookup_table.astype(output_type)\n    assert np.diff(lookup_table).min() &gt;= 0, \"non-monotonic lookup generated\"\n    return lookup\n</code></pre>"},{"location":"api/codec/#make_inverse_lookup","title":"make_inverse_lookup","text":""},{"location":"api/codec/#anscombe_transform.codec.make_inverse_lookup","title":"<code>make_inverse_lookup(lookup_table, output_type='int16')</code>","text":"<p>Compute the inverse lookup table for a monotonic forward lookup table.</p> <p>Parameters:</p> Name Type Description Default <code>lookup_table</code> <code>ndarray</code> <p>Monotonic forward lookup table.</p> required <code>output_type</code> <code>str</code> <p>NumPy dtype string for output array, by default \"int16\".</p> <code>'int16'</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Inverse lookup table that maps encoded values back to original values.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>def make_inverse_lookup(lookup_table: np.ndarray, output_type=\"int16\") -&gt; np.ndarray:\n    \"\"\"\n    Compute the inverse lookup table for a monotonic forward lookup table.\n\n    Parameters\n    ----------\n    lookup_table : np.ndarray\n        Monotonic forward lookup table.\n    output_type : str, optional\n        NumPy dtype string for output array, by default \"int16\".\n\n    Returns\n    -------\n    np.ndarray\n        Inverse lookup table that maps encoded values back to original values.\n    \"\"\"\n    _, inv1 = np.unique(lookup_table, return_index=True)  # first entry\n    _, inv2 = np.unique(lookup_table[::-1], return_index=True)  # last entry\n    inverse = (inv1 + lookup_table.size - 1 - inv2) / 2\n    return inverse.astype(output_type)\n</code></pre>"},{"location":"api/codec/#lookup","title":"lookup","text":""},{"location":"api/codec/#anscombe_transform.codec.lookup","title":"<code>lookup(movie, lookup_table)</code>","text":"<p>Apply lookup table to movie with boundary clamping.</p> <p>Parameters:</p> Name Type Description Default <code>movie</code> <code>ndarray</code> <p>Input array to transform.</p> required <code>lookup_table</code> <code>ndarray</code> <p>Lookup table for transformation.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Transformed array with values from lookup table.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>def lookup(movie: np.ndarray, lookup_table: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Apply lookup table to movie with boundary clamping.\n\n    Parameters\n    ----------\n    movie : np.ndarray\n        Input array to transform.\n    lookup_table : np.ndarray\n        Lookup table for transformation.\n\n    Returns\n    -------\n    np.ndarray\n        Transformed array with values from lookup table.\n    \"\"\"\n    return lookup_table[np.maximum(0, np.minimum(movie, lookup_table.size - 1))]\n</code></pre>"},{"location":"api/estimate/","title":"Estimation API Reference","text":"<p>This page documents the parameter estimation functions.</p>"},{"location":"api/estimate/#compute_conversion_gain","title":"compute_conversion_gain","text":""},{"location":"api/estimate/#anscombe_transform.estimate.compute_conversion_gain","title":"<code>compute_conversion_gain(movie, count_weight_gamma=0.2)</code>","text":"<p>Calculate photon sensitivity and zero level from temporal variance analysis.</p> <p>This function estimates camera parameters by fitting the noise transfer function from temporal variance. It uses HuberRegressor to robustly fit the relationship between mean signal and variance.</p> <p>Parameters:</p> Name Type Description Default <code>movie</code> <code>ndarray</code> <p>A movie in the format (time, height, width).</p> required <code>count_weight_gamma</code> <code>float</code> <p>Weighting exponent for pixel counts in regression, by default 0.2. - 0.0: weigh each intensity level equally - 1.0: weigh each intensity in proportion to pixel counts</p> <code>0.2</code> <p>Returns:</p> Type Description <code>dict</code> <p><code>ConversionGainConfig</code></p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If movie is not 3-dimensional or if insufficient intensity range is present.</p> Source code in <code>src/anscombe_transform/estimate.py</code> <pre><code>def compute_conversion_gain(movie: np.array, count_weight_gamma: float = 0.2) -&gt; ConversionGainConfig:\n    \"\"\"\n    Calculate photon sensitivity and zero level from temporal variance analysis.\n\n    This function estimates camera parameters by fitting the noise transfer function\n    from temporal variance. It uses HuberRegressor to robustly fit the relationship\n    between mean signal and variance.\n\n    Parameters\n    ----------\n    movie : np.ndarray\n        A movie in the format (time, height, width).\n    count_weight_gamma : float, optional\n        Weighting exponent for pixel counts in regression, by default 0.2.\n        - 0.0: weigh each intensity level equally\n        - 1.0: weigh each intensity in proportion to pixel counts\n\n    Returns\n    -------\n    dict\n        `ConversionGainConfig`\n\n    Raises\n    ------\n    AssertionError\n        If movie is not 3-dimensional or if insufficient intensity range is present.\n    \"\"\"\n    assert movie.ndim == 3, (\n        f\"Thee dimensions (Time x Height x Width) of grayscale movie expected, got {movie.ndim} dimensions\"\n    )\n\n    # assume that negative values are due to noise\n    movie = np.maximum(0, movie.astype(np.int32, copy=False))\n    intensity = (movie[:-1, :, :] + movie[1:, :, :] + 1) // 2\n    difference = movie[:-1, :, :].astype(np.float32) - movie[1:, :, :]\n\n    select = intensity &gt; 0  # discard non-positive values\n    intensity = intensity[select]\n    difference = difference[select]\n\n    counts = np.bincount(intensity.flatten())\n    bins = _longest_run(\n        counts &gt; 0.01 * counts.mean()\n    )  # consider only bins with at least 1% of mean counts\n    bins = slice(max(bins.stop * 3 // 100, bins.start), bins.stop)\n    assert bins.stop - bins.start &gt; 100, (\n        \"The image does not have a sufficient range of intensities to compute the noise transfer function.\"\n    )\n\n    counts = counts[bins]\n    idx = (intensity &gt;= bins.start) &amp; (intensity &lt; bins.stop)\n    variance = (\n        np.bincount(\n            intensity[idx] - bins.start,\n            weights=(difference[idx] ** 2) / 2,\n        )\n        / counts\n    )\n    model = Regressor()\n    model.fit(np.c_[bins], variance, counts**count_weight_gamma)\n    conversion_gain = model.coef_[0]\n    zero_level = -model.intercept_ / model.coef_[0]\n\n    return {\n        \"model\": model,\n        \"counts\":  counts,\n        \"min_intensity\": bins.start,\n        \"max_intensity\" : bins.stop,\n        \"variance\": variance,\n        \"conversion_gain\": conversion_gain,\n        \"zero_level\": zero_level,\n    }\n</code></pre>"},{"location":"examples/workbook/","title":"Complete Workflow Example","text":"<p>This page provides a complete end-to-end example of using the Anscombe Transform codec.</p> <p>For an interactive version, see the Jupyter notebook in the repository.</p>"},{"location":"examples/workbook/#overview","title":"Overview","text":"<p>This example demonstrates:</p> <ol> <li>Loading sample photon-limited data</li> <li>Estimating codec parameters</li> <li>Compressing data with Zarr V3</li> <li>Validating reconstruction quality</li> <li>Measuring compression ratios</li> </ol>"},{"location":"examples/workbook/#setup","title":"Setup","text":"<pre><code>import numpy as np\nimport zarr\nfrom anscombe_transform import AnscombeTransformV3, compute_conversion_gain\nimport matplotlib.pyplot as plt\n</code></pre>"},{"location":"examples/workbook/#generate-sample-data","title":"Generate Sample Data","text":"<p>First, let's create synthetic data that mimics photon-limited imaging:</p> <pre><code># Parameters for synthetic data\nn_frames = 30\nheight, width = 120, 120\nmean_photon_rate = 5.0  # Average photons per pixel (exponential distribution of rates)\nzero_level = -10.0   # camera baseline\nconversion_gain = 2.5  # levels per photon\n\n# Generate Poisson-distributed photon counts\nphoton_rate = np.random.exponential(scale=5, size=(1, height, width))\nphoton_counts = np.random.poisson(lam=np.tile(photon_rate, (n_frames, 1, 1)))\nmeasured_signal = photon_counts + np.random.randn(*size) * 0.2\n\n# Convert to camera signal\ncamera_signal = (measured_signal * conversion_gain + zero_level).astype('int16')\n\nprint(f\"Data shape: {camera_signal.shape}\")\nprint(f\"Data range: [{camera_signal.min()}, {camera_signal.max()}]\")\nprint(f\"Data dtype: {camera_signal.dtype}\")\n</code></pre>"},{"location":"examples/workbook/#estimate-parameters","title":"Estimate Parameters","text":"<p>Now estimate the codec parameters from the data:</p> <pre><code># Estimate parameters from the movie\nresult = compute_conversion_gain(camera_signal)\n\nestimated_gain = result['sensitivity']\nestimated_zero = result['zero_level']\n\nprint(f\"\\nTrue parameters:\")\nprint(f\"  Conversion gain: {conversion_gain:.3f} units/photon\")\nprint(f\"  Zero level: {zero_level:.1f} \")\n\nprint(f\"\\nEstimated parameters:\")\nprint(f\"  Conversion gain: {estimated_gain:.3f} units/photon\")\nprint(f\"  Zero level: {estimated_zero:.1f}\")\n\nprint(f\"\\nEstimation error:\")\nprint(f\"  Gain error: {abs(estimated_gain - conversion_gain):.3f} units/photon\")\nprint(f\"  Zero level error: {abs(estimated_zero - zero_level):.1f} units\")\n</code></pre>"},{"location":"examples/workbook/#visualize-noise-model","title":"Visualize Noise Model","text":"<p>Plot the noise model fit:</p> <pre><code># Compute mean and variance\nmean_signal = np.mean(camera_signal, axis=0)\nvariance = np.var(camera_signal, axis=0)\n\n# Create scatter plot\nplt.figure(figsize=(10, 6))\nplt.scatter(mean_signal.ravel()[::100], variance.ravel()[::100],\n            alpha=0.5, s=1, label='Data')\n\n# Plot fitted line\nmean_range = np.array([mean_signal.min(), mean_signal.max()])\nvariance_fit = estimated_gain * (mean_range - estimated_zero)\nplt.plot(mean_range, variance_fit, 'r-', linewidth=2,\n         label=f'Fit: var = {estimated_gain:.2f} * (mean - {estimated_zero:.1f})')\n\nplt.xlabel('Mean Signal (ADU)')\nplt.ylabel('Variance (ADU\u00b2)')\nplt.title('Noise Transfer Function')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n</code></pre>"},{"location":"examples/workbook/#compress-with-anscombe-codec","title":"Compress with Anscombe Codec","text":"<p>Create a Zarr array with the codec:</p> <pre><code># Create codec with estimated parameters\ncodec = AnscombeTransformV3(\n    zero_level=estimated_zero,\n    conversion_gain=estimated_gain,\n    encoded_dtype='uint8'\n)\n\n# Create Zarr V3 array\nstore = zarr.storage.MemoryStore()\ncompressed_array = zarr.create(\n    store=store,\n    shape=camera_signal.shape,\n    chunks=(10, 512, 512),\n    dtype='int16',\n    filters=[codec],\n    compressor={'id': 'blosc', 'cname': 'zstd', 'clevel': 5},\n    zarr_format=3\n)\n\n# Write data\ncompressed_array[:] = camera_signal\n\nprint(f\"Compression complete!\")\n</code></pre>"},{"location":"examples/workbook/#validate-reconstruction","title":"Validate Reconstruction","text":"<p>Check the quality of reconstruction:</p> <pre><code># Read back compressed data\nreconstructed = compressed_array[:]\n\n# Compute reconstruction error\nerror = camera_signal - reconstructed\nabs_error = np.abs(error)\n\nprint(f\"\\nReconstruction Quality:\")\nprint(f\"  Max absolute error: {abs_error.max():.2f} ADU\")\nprint(f\"  Mean absolute error: {abs_error.mean():.2f} ADU\")\nprint(f\"  RMS error: {np.sqrt(np.mean(error**2)):.2f} ADU\")\nprint(f\"  Expected noise (1 photon): {estimated_gain:.2f} ADU\")\nprint(f\"  Error as fraction of noise: {abs_error.mean() / estimated_gain:.2f}\")\n\n# Visualize error distribution\nplt.figure(figsize=(12, 4))\n\nplt.subplot(131)\nplt.imshow(camera_signal[0], cmap='gray', vmin=0, vmax=500)\nplt.title('Original Frame')\nplt.colorbar(label='ADU')\n\nplt.subplot(132)\nplt.imshow(reconstructed[0], cmap='gray', vmin=0, vmax=500)\nplt.title('Reconstructed Frame')\nplt.colorbar(label='ADU')\n\nplt.subplot(133)\nplt.imshow(error[0], cmap='RdBu_r', vmin=-10, vmax=10)\nplt.title('Error (Original - Reconstructed)')\nplt.colorbar(label='ADU')\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"examples/workbook/#measure-compression-ratio","title":"Measure Compression Ratio","text":"<p>Calculate the compression achieved:</p> <pre><code># Original size\noriginal_size = camera_signal.nbytes\n\n# Compressed size (estimate from store)\ncompressed_size = sum(len(v) for v in store.values())\n\ncompression_ratio = original_size / compressed_size\n\nprint(f\"\\nCompression Statistics:\")\nprint(f\"  Original size: {original_size / 1024**2:.2f} MB\")\nprint(f\"  Compressed size: {compressed_size / 1024**2:.2f} MB\")\nprint(f\"  Compression ratio: {compression_ratio:.2f}x\")\nprint(f\"  Space saved: {(1 - 1/compression_ratio) * 100:.1f}%\")\n</code></pre>"},{"location":"examples/workbook/#compare-different-compressors","title":"Compare Different Compressors","text":"<p>Test various compressor configurations:</p> <pre><code>compressors = [\n    {'name': 'Blosc+Zstd', 'config': {'id': 'blosc', 'cname': 'zstd', 'clevel': 5}},\n    {'name': 'Blosc+LZ4', 'config': {'id': 'blosc', 'cname': 'lz4', 'clevel': 3}},\n    {'name': 'Blosc+Zlib', 'config': {'id': 'blosc', 'cname': 'zlib', 'clevel': 9}},\n]\n\nresults = []\n\nfor comp in compressors:\n    store = zarr.storage.MemoryStore()\n    arr = zarr.create(\n        store=store,\n        shape=camera_signal.shape,\n        chunks=(10, 512, 512),\n        dtype='int16',\n        filters=[codec],\n        compressor=comp['config'],\n        zarr_format=3\n    )\n    arr[:] = camera_signal\n\n    compressed_size = sum(len(v) for v in store.values())\n    ratio = original_size / compressed_size\n\n    results.append({\n        'name': comp['name'],\n        'size_mb': compressed_size / 1024**2,\n        'ratio': ratio\n    })\n\n    print(f\"{comp['name']:15s}: {ratio:.2f}x compression, {compressed_size / 1024**2:.2f} MB\")\n\n# Plot comparison\nplt.figure(figsize=(10, 5))\nnames = [r['name'] for r in results]\nratios = [r['ratio'] for r in results]\nplt.bar(names, ratios)\nplt.ylabel('Compression Ratio')\nplt.title('Compression Performance by Algorithm')\nplt.grid(axis='y', alpha=0.3)\nplt.show()\n</code></pre>"},{"location":"examples/workbook/#summary","title":"Summary","text":"<p>This example demonstrated:</p> <ul> <li>\u2705 Parameter estimation with ~1% accuracy</li> <li>\u2705 Reconstruction error below 1 photon equivalent</li> <li>\u2705 5-8x compression ratios</li> <li>\u2705 Successful integration with Zarr V3</li> </ul>"},{"location":"examples/workbook/#next-steps","title":"Next Steps","text":"<ul> <li>Try with your own data</li> <li>Experiment with different <code>beta</code> values</li> <li>Compare with other compression algorithms</li> <li>Use with remote storage backends</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#from-pypi","title":"From PyPI","text":"<p>The recommended way to install the Anscombe Transform codec is via pip:</p> <pre><code>pip install anscombe-transform\n</code></pre>"},{"location":"getting-started/installation/#development-installation","title":"Development Installation","text":"<p>This project uses hatch for managing the development environment.</p> <p>You can install <code>hatch</code> via pip:</p> <pre><code>pip install hatch\n</code></pre> <p>Or directly.</p> <pre><code># Run tests across all environments\nhatch run test:pytest tests/\n\n# Run tests for a specific Python/NumPy version\nhatch run test.py3.11-2.2:pytest tests/\n\n# Enter a development shell\nhatch shell\n</code></pre> <p>See the Contributing Guide for more details on development setup.</p>"},{"location":"getting-started/quick-start/","title":"Quick Start","text":"<p>This guide will help you get started with the Anscombe Transform codec for compressing photon-limited movies.</p>"},{"location":"getting-started/quick-start/#basic-usage-with-zarr-v3","title":"Basic Usage with Zarr V3","text":"<pre><code>import zarr\nimport numpy as np\nfrom anscombe_transform import AnscombeTransformV3\n\n# Synthesize data with Poisson noise - simulating photon-limited microscopy data\nn_frames, height, width = 50, 256, 256\nmean_photon_rate = 5.0  # Average photons per pixel (exponential distribution of rates)\nzero_level = 20.0   # camera baseline\nconversion_gain = 30.0  # levels per photon\nphoton_rate = np.random.exponential(scale=mean_photon_rate, size=(1, height, width))\nphoton_counts = np.random.poisson(np.tile(photon_rate, (n_frames, 1, 1)))\nmeasured_signal = photon_counts + np.random.randn(*size) * 0.2\n\ndata = (zero_level + conversion_gain * measured_signal).astype('int16')\n\n# Create a Zarr array with the Anscombe codec\nstore = zarr.storage.MemoryStore()\narr = zarr.create(\n    store=store,\n    shape=data.shape,\n    chunks=(12, 160, 80),\n    dtype='int16',\n    filters=[AnscombeTransformV3(zero_level=zero_level, conversion_gain=conversion_gain)],\n    zarr_format=3\n)\n\n# Write data\narr[:] = data\n\n# Read data back\nrecovered = arr[:]\n\n# Verify roundtrip accuracy\nprint(f\"Max difference: {np.abs(data - recovered).max()}\")\n</code></pre>"},{"location":"getting-started/quick-start/#using-with-zarr-v2","title":"Using with Zarr V2","text":"<pre><code>from anscombe_transform import AnscombeTransformV2\nimport zarr\n\n# Create array with V2 codec\narr = zarr.open_array(\n    'data.zarr',\n    mode='w',\n    shape=data.shape,\n    chunks=(12, 160, 80),\n    dtype='int16',\n    compressor=AnscombeTransformV2(zero_level=zero_level, conversion_gain=conversion_gain)\n)\n\n# Write and read data\narr[:] = data\nrecovered = arr[:]\n</code></pre>"},{"location":"getting-started/quick-start/#estimating-parameters-from-data","title":"Estimating Parameters from Data","text":"<p>If you don't know the <code>zero_level</code> and <code>conversion_gain</code> parameters, you can estimate them from your data:</p> <pre><code>from anscombe_transform import compute_conversion_gain\nimport numpy as np\n\n# Load your movie data as (time, height, width)\nmovie = data\n\n# Estimate parameters\nresult = compute_conversion_gain(data)\n\nprint(f\"Estimated conversion gain: {result['sensitivity']:.3f}\")\nprint(f\"Estimated zero level: {result['zero_level']:.3f}\")\n\n# Use estimated parameters in codec\ncodec = AnscombeTransformV3(\n    zero_level=result['zero_level'],\n    conversion_gain=result['sensitivity']\n)\n</code></pre>"},{"location":"getting-started/quick-start/#combining-with-other-compressors","title":"Combining with Other Compressors","text":"<p>The Anscombe codec is typically used as a filter before compression:</p> <pre><code>import zarr\nfrom numcodecs import Blosc\nfrom anscombe_transform import AnscombeTransformV3\n\n# For Zarr V3, use filters + codecs\narr = zarr.create(\n    shape=data.shape,\n    chunks=(10, 512, 512),\n    dtype='int16',\n    filters=[AnscombeTransformV3(zero_level=zero_level, conversion_gain=conversion_gain)],\n    compressor={'id': 'blosc', 'cname': 'zstd', 'clevel': 5},\n    zarr_format=3\n)\n</code></pre>"},{"location":"getting-started/quick-start/#key-parameters","title":"Key Parameters","text":"<ul> <li><code>zero_level</code>: The signal value when no photons are detected. This is the baseline offset in your camera sensor.</li> <li><code>conversion_gain</code> (also called <code>photon_sensitivity</code>): How many signal units correspond to one photon. For example, if your camera reports 2.5 levels increase in signal per photon, use <code>conversion_gain=2.5</code>.</li> <li><code>encoded_dtype</code>: The data type for encoded values (default: <code>uint8</code>). Use <code>uint8</code> for maximum compression.</li> <li><code>decoded_dtype</code>: The data type for decoded values (default: inferred from data).</li> </ul>"},{"location":"getting-started/quick-start/#next-steps","title":"Next Steps","text":"<ul> <li>Learn more in the User Guide</li> <li>See Parameter Estimation for details on computing parameters</li> <li>Check out the full Workbook Example</li> <li>Explore the API Reference</li> </ul>"},{"location":"spec/anscombe_transform/","title":"<code>anscombe-transform</code> Codec","text":"<p>This specification defines an array-&gt;array codec that encodes an input array using the Anscombe transform followed by an optional data type casting operations and decodes using the inverted type cast and the inverse Anscombe transform. This transformation is not generally lossless, but is useful as for conditioning data prior to compression.</p>"},{"location":"spec/anscombe_transform/#anscombe-transform","title":"Anscombe transform","text":"<p>The Anscombe transform is bijection from a Poisson-distributed variable to an approximately Gaussian-distributed variable with a variance of 1.</p> <p>This transformation is useful in sensing applications to mitigate shot noise. Shot noise is typically modelled as a Poisson process. The variance of a Poisson-distributed signal scales with its mean. The Anscombe transform maps a Poisson-distributed signal to a Gaussian-distributed signal with a variance near 1. Decoupling the mean of the signal from its variance facilitates noise removal and data compression, the latter of which is the intended application of this codec.</p>"},{"location":"spec/anscombe_transform/#codec-algorithm","title":"Codec algorithm","text":""},{"location":"spec/anscombe_transform/#encoding","title":"Encoding","text":""},{"location":"spec/anscombe_transform/#parameters","title":"Parameters","text":"<p>In addition to the input array, the encoding procedure takes the following parameters:</p> name type <code>conversion_gain</code> positive real number <code>zero_level</code> real number <code>beta</code> positive real number <code>encoded_dtype</code> Zarr V3 data type"},{"location":"spec/anscombe_transform/#algorithm","title":"Algorithm","text":"<p>For each element $x$ of the input array, an output value $y$ is generated via the following procedure:</p> <ol> <li> <p>$x$ is normalized by subtracting $\\text{zero_level}$ and then dividing by $\\text{conversion_gain}$. The result of this transformation, called $x_{\\text{norm}}$, now represents a quantity of observed events. </p> <p>Schematically:</p> <p>$x_{\\text{norm}} := \\frac{x - \\text{zero_level}}{\\text{conversion_gain}}$</p> </li> <li> <p>If $x_{\\text{norm}}$ is non-negative, we apply the Anscombe transform, multiply by a scaling factor, and add an offset, and bind $\\text{result}$ to the result. Schematically, the transformation is as follows:</p> </li> </ol> <p>$$ \\text{result} := \\frac{1}{\\text{beta}} \\left(\\frac{\\text{zero_level}}{\\text{conversion_gain} \\, *  \\sqrt{3/8}} + 2 \\left( \\sqrt{x_{\\text{norm}} + \\tfrac{3}{8}} - \\sqrt{\\tfrac{3}{8}} \\right)\\right) $$</p> <p>The additional scaling and offset factors ensure that the transform maps the $\\text{zero_level}$ value to $0$, and also that the transform is continuous around 0, because we will use linear extrapolation to resolve negative values of $x_{\\text{norm}}$.</p> <p>When $x_{\\text{norm}}$ is negative, we bind $\\text{result}$ to $x$ divided by the product of $\\text{beta}$ , $\\text{conversion_gain}$, and $\\sqrt{3/8}$. This is effectively linear extrapolation from 0 in the negative direction. Schematically:</p> <p>$$ \\text{result} :=      \\frac         {x}         {\\text{beta} * \\text{conversion_gain} *\\sqrt{3/8} }  $$</p> <p>If <code>encoded_dtype</code> denotes an integer data type, then $\\text{result}$ is rounded before the data type casting procedure.</p>"},{"location":"spec/anscombe_transform/#reference-python-function","title":"Reference python function","text":"<p>The above procedure is implemented in the following reference Python function:</p> <pre><code># /// script\n# requires-python = \"&gt;=3.11\"\n# dependencies = [\"zarr&gt;=3.1.1\", \"numpy==2.2\"]\n# ///\nimport numpy as np\nfrom zarr.core.dtype import ZDType\ndef anscombe_transform(x, conversion_gain: float, zero_level: float, beta: float, encoded_dtype: ZDType):\n    # Convert to event units\n    event_rate = (x - zero_level) / conversion_gain\n\n    zero_slope = 1.0 / (beta * np.sqrt(3.0 / 8.0))\n    offset = zero_level * zero_slope / conversion_gain\n\n    if event_rate &lt; 0:\n        # Linear extrapolation\n        result = offset + event_rate * zero_slope\n    else:\n        # Anscombe transform\n        result = offset + (2.0 / beta) * (np.sqrt(event_rate + 3.0 / 8.0) - np.sqrt(3.0 / 8.0))\n\n    # When converting from a floating point to an integer data type,\n    # values should be rounded prior to type conversion\n    np_dtype = encoded_dtype.to_native_dtype()\n    if np_dtype.kind in {\"i\", \"u\"}:\n        return np.astype(np.round(result), np_dtype)\n    return np.astype(result, np_dtype)\n</code></pre>"},{"location":"spec/anscombe_transform/#decoding","title":"Decoding","text":""},{"location":"spec/anscombe_transform/#algorithm_1","title":"Algorithm","text":"<p>To decode Anscombe-transformed data, invert the encoding algorithm. Depending on the choice of output data type, the decoded data may not match exactly the input.</p>"},{"location":"spec/anscombe_transform/#parameters_1","title":"Parameters","text":"<p>In addition to the input array, the decoding procedure takes the following parameters:</p> name type <code>conversion_gain</code> positive real number <code>zero_level</code> real number <code>beta</code> positive real number <code>decoded_dtype</code> Zarr V3 data type <p>These are the same as the parameters used for the encoding procedure minus the <code>encoded_dtype</code>; the <code>decoded_dtype</code> is required instead.</p>"},{"location":"spec/anscombe_transform/#codec-metadata","title":"Codec metadata","text":"field type required notes <code>name</code> literal <code>\"anscombe-transform\"</code> yes <code>configuration</code> anscombe transform configuration yes"},{"location":"spec/anscombe_transform/#configuration-metadata","title":"Configuration metadata","text":"field type required notes <code>zero_level</code> number yes The value in the input array that corresponds to 0 detected events. <code>beta</code> positive number yes Ratio of quantization step to noise. Typical values are between 0.5 and 2. <code>conversion_gain</code> positive number yes The magnitude of a single recorded event in the input data <code>decoded_dtype</code> Zarr V3 data type metadata yes The Zarr data type of the input array. <code>encoded_dtype</code> Zarr V3 data type metadata yes The Zarr data type of the output array."},{"location":"spec/anscombe_transform/#supported-array-data-types","title":"Supported array data types","text":"<p>This codec is compatible with array data types that model real numbers or a subset thereof. </p>"},{"location":"user-guide/overview/","title":"Overview","text":""},{"location":"user-guide/overview/#the-anscombe-transform","title":"The Anscombe Transform","text":"<p>The Anscombe Transform is a variance-stabilizing transformation specifically designed for data with Poisson noise. In photon-limited imaging, the noise variance equals the signal mean (characteristic of Poisson statistics), which makes compression difficult because different intensity levels have different noise characteristics.</p>"},{"location":"user-guide/overview/#the-problem","title":"The Problem","text":"<p>In photon-limited data: - Low intensity regions have low noise variance - High intensity regions have high noise variance - This heteroscedastic noise makes efficient compression challenging</p>"},{"location":"user-guide/overview/#the-solution","title":"The Solution","text":"<p>The Anscombe Transform applies a square-root-like transformation that: 1. Equalizes noise variance across all intensity levels 2. Reduces the number of unique grayscale values needed 3. Improves compressibility without losing signal accuracy</p> <p>Mathematically, the transform is:</p> <pre><code>f(x) = 2 * sqrt(x + 3/8)\n</code></pre> <p>For our codec, we adapt this to account for camera parameters:</p> <pre><code>encoded = quantize(2 * sqrt((data - zero_level) / conversion_gain + 3/8))\n</code></pre>"},{"location":"user-guide/overview/#codec-architecture","title":"Codec Architecture","text":"<p>The codec is implemented in two versions to support both Zarr V2 and V3:</p>"},{"location":"user-guide/overview/#zarr-v2-anscombetransformv2","title":"Zarr V2: <code>AnscombeTransformV2</code>","text":"<ul> <li>Implements the <code>numcodecs.Codec</code> interface</li> <li>Used as a compressor in Zarr V2 arrays</li> <li>Registered with ID <code>\"anscombe-v1\"</code></li> </ul>"},{"location":"user-guide/overview/#zarr-v3-anscombetransformv3","title":"Zarr V3: <code>AnscombeTransformV3</code>","text":"<ul> <li>Implements the <code>ArrayArrayCodec</code> interface</li> <li>Used as a filter before compression in Zarr V3 arrays</li> <li>Registered with the same ID <code>\"anscombe-v1\"</code></li> </ul> <p>Both share the same core <code>encode()</code> and <code>decode()</code> functions, ensuring consistent behavior.</p>"},{"location":"user-guide/overview/#how-it-works","title":"How It Works","text":""},{"location":"user-guide/overview/#encoding-pipeline","title":"Encoding Pipeline","text":"<ol> <li>Normalize: Convert raw data to photon counts using <code>conversion_gain</code> and <code>zero_level</code></li> <li>Transform: Apply the Anscombe Transform to stabilize variance</li> <li>Quantize: Discretize the transformed values to <code>encoded_dtype</code> (typically <code>uint8</code>)</li> <li>Compress: Apply additional compression (e.g., Blosc, Zstd)</li> </ol>"},{"location":"user-guide/overview/#decoding-pipeline","title":"Decoding Pipeline","text":"<ol> <li>Decompress: Uncompress the data</li> <li>Lookup: Apply inverse transform via lookup table</li> <li>Denormalize: Convert back to original units using <code>conversion_gain</code> and <code>zero_level</code></li> </ol>"},{"location":"user-guide/overview/#lookup-tables","title":"Lookup Tables","text":"<p>The codec uses pre-computed lookup tables for efficiency: - Forward lookup: Maps input values to transformed values - Inverse lookup: Maps transformed values back to original values</p> <p>These tables are computed once during codec initialization and reused for all encode/decode operations.</p>"},{"location":"user-guide/overview/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"user-guide/overview/#compression-ratios","title":"Compression Ratios","text":"<p>Typical compression ratios (Anscombe + Blosc/Zstd): - 3-8x for typical multiphoton microscopy data - 6-10x for astronomy data - 3-6x for radiography data</p> <p>The exact ratio depends on: - Signal-to-noise ratio of the data - Spatial correlation in the images - Choice of secondary compressor</p>"},{"location":"user-guide/overview/#speed","title":"Speed","text":"<p>The codec is designed for speed: - Encoding: ~500-1000 MB/s (single-threaded) - Decoding: ~800-1500 MB/s (single-threaded) - Scales well with chunk-based parallel processing</p>"},{"location":"user-guide/overview/#accuracy","title":"Accuracy","text":"<p>The codec is designed to be nearly lossless for photon-limited data: - Typical error: &lt; 1 photon per pixel - Error scales with <code>conversion_gain</code> and quantization (<code>beta</code> parameter) - For well-chosen parameters, reconstruction error is below the noise floor</p>"},{"location":"user-guide/overview/#when-to-use-this-codec","title":"When to Use This Codec","text":""},{"location":"user-guide/overview/#good-use-cases","title":"Good Use Cases \u2705","text":"<ul> <li>Multiphoton microscopy movies</li> <li>Astronomy images with photon counting detectors</li> <li>Radiography/X-ray imaging</li> <li>Any data with Poisson noise where signal \u2248 variance</li> <li>Data where you can estimate or know <code>conversion_gain</code> and <code>zero_level</code></li> </ul>"},{"location":"user-guide/overview/#not-recommended","title":"Not Recommended \u274c","text":"<ul> <li>Data without Poisson noise (e.g., pre-processed images)</li> <li>Data where camera parameters are unknown and can't be estimated</li> <li>Data with very high dynamic range (&gt; 16-bit)</li> <li>Data that has already been normalized or transformed</li> </ul>"},{"location":"user-guide/overview/#next-steps","title":"Next Steps","text":"<ul> <li>Parameter Estimation Guide</li> <li>Zarr V2 Integration</li> <li>Zarr V3 Integration</li> </ul>"},{"location":"user-guide/parameter-estimation/","title":"Parameter Estimation","text":"<p>To use the Anscombe Transform codec effectively, you need two key parameters:</p> <ol> <li><code>zero_level</code>: The baseline signal value when no photons are detected</li> <li><code>conversion_gain</code> (also called <code>photon_sensitivity</code>): The conversion factor from signal units to photon counts</li> </ol> <p>This guide explains how to estimate these parameters from your data.</p>"},{"location":"user-guide/parameter-estimation/#the-compute_conversion_gain-function","title":"The <code>compute_conversion_gain()</code> Function","text":"<p>The codec provides a built-in parameter estimation function:</p> <pre><code>from anscombe_transform import compute_conversion_gain\nimport numpy as np\n\n# Load your movie data as (time, height, width)\nmovie = load_my_movie()  # Shape: (n_frames, height, width)\n\n# Estimate parameters\nresult = compute_conversion_gain(movie)\n\nprint(f\"Conversion gain: {result['sensitivity']:.3f}\")\nprint(f\"Zero level: {result['zero_level']:.3f}\")\n</code></pre>"},{"location":"user-guide/parameter-estimation/#input-requirements","title":"Input Requirements","text":"<p>The <code>compute_conversion_gain()</code> function expects: - Shape: <code>(time, height, width)</code> - temporal axis must be first - Data type: Integer or float - Minimum frames: At least 10-20 frames for reliable estimation - Static scene: Works best when the scene doesn't change much over time</p>"},{"location":"user-guide/parameter-estimation/#how-it-works","title":"How It Works","text":"<p>The function uses the noise transfer function approach:</p> <ol> <li>Compute temporal variance: Calculate pixel-wise variance across time</li> <li>Compute temporal mean: Calculate pixel-wise mean across time</li> <li>Fit noise model: Use HuberRegressor to fit <code>variance = slope * mean + intercept</code></li> </ol> <p>For Poisson noise: <code>variance = conversion_gain * (mean - zero_level)</code></p> <p>Therefore: - <code>conversion_gain = slope</code> - <code>zero_level = -intercept / slope</code></p>"},{"location":"user-guide/parameter-estimation/#return-value","title":"Return Value","text":"<p>The function returns a dictionary with:</p> <pre><code>{\n    'sensitivity': float,      # The conversion gain (photons per signal unit)\n    'zero_level': float,       # The baseline signal level\n    'variance': ndarray,       # Computed pixel-wise variance\n    'model': HuberRegressor    # The fitted regression model\n}\n</code></pre>"},{"location":"user-guide/parameter-estimation/#manual-parameter-estimation","title":"Manual Parameter Estimation","text":"<p>If you know your camera specifications, you can compute the parameters manually:</p>"},{"location":"user-guide/parameter-estimation/#zero-level","title":"Zero Level","text":"<p>The zero level is typically: - Dark current: The signal level with the shutter closed - Bias level: The electronic offset added to prevent negative values</p> <p>To measure: 1. Capture several frames with no light (shutter closed or lens cap on) 2. Compute the median value across all pixels and frames</p> <pre><code>dark_frames = capture_dark_frames(n=20)\nzero_level = np.median(dark_frames)\n</code></pre>"},{"location":"user-guide/parameter-estimation/#conversion-gain","title":"Conversion Gain","text":"<p>The conversion gain depends on your camera's specifications:</p> <pre><code># If you know electrons per ADU:\nelectrons_per_adu = 2.5  # From camera spec sheet\nquantum_efficiency = 0.9  # Photons to electrons conversion\n\nconversion_gain = electrons_per_adu / quantum_efficiency\n</code></pre> <p>Or measure from a uniform illumination:</p> <pre><code># Capture frames of uniform illumination\nuniform_frames = capture_uniform_frames(n=100)\n\n# Compute mean and variance for each pixel\nmean = np.mean(uniform_frames, axis=0)\nvariance = np.var(uniform_frames, axis=0)\n\n# For Poisson noise: variance = gain * (mean - zero)\n# Fit a line through the origin after subtracting zero level\nconversion_gain = np.median(variance / (mean - zero_level))\n</code></pre>"},{"location":"user-guide/parameter-estimation/#validation","title":"Validation","text":"<p>After estimating parameters, validate them:</p> <pre><code>from anscombe_transform import AnscombeTransformV3\n\n# Create codec with estimated parameters\ncodec = AnscombeTransformV3(\n    zero_level=result['zero_level'],\n    conversion_gain=result['sensitivity']\n)\n\n# Test on a sample frame\nframe = movie[0]\nencoded = codec.encode(frame)\ndecoded = codec.decode(encoded)\n\n# Check reconstruction error\nerror = np.abs(frame - decoded)\nmax_error = np.max(error)\nmean_error = np.mean(error)\n\nprint(f\"Max error: {max_error:.2f} ADU\")\nprint(f\"Mean error: {mean_error:.2f} ADU\")\nprint(f\"Expected noise (1 photon): {result['sensitivity']:.2f} ADU\")\n\n# Error should be less than ~1 photon equivalent\nassert max_error &lt; 2 * result['sensitivity']\n</code></pre>"},{"location":"user-guide/parameter-estimation/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/parameter-estimation/#data-collection","title":"Data Collection","text":"<ol> <li>Use multiple frames: 20+ frames for reliable statistics</li> <li>Avoid motion: Use static scenes or stabilized video</li> <li>Cover dynamic range: Include both bright and dark regions</li> <li>Use raw data: Don't use pre-processed or normalized data</li> </ol>"},{"location":"user-guide/parameter-estimation/#parameter-refinement","title":"Parameter Refinement","text":"<ol> <li>Check fit quality: Inspect <code>result['model'].score()</code> (R\u00b2 should be &gt; 0.95)</li> <li>Visualize fit: Plot variance vs. mean to verify linear relationship</li> <li>Test reconstruction: Verify that encoding/decoding preserves data quality</li> </ol>"},{"location":"user-guide/parameter-estimation/#common-issues","title":"Common Issues","text":"<p>Negative zero level: Usually indicates pre-processed data or incorrect bias subtraction. Check if your data has been normalized.</p> <p>Very high conversion gain (&gt; 10): May indicate the data is already in photon units or has been scaled.</p> <p>Poor R\u00b2 score (&lt; 0.9): Could mean: - Too much motion in the scene - Non-Poisson noise dominates (e.g., readout noise) - Not enough temporal variation</p>"},{"location":"user-guide/parameter-estimation/#example-workflow","title":"Example Workflow","text":"<pre><code>import numpy as np\nfrom anscombe_transform import compute_conversion_gain, AnscombeTransformV3\nimport zarr\n\n# 1. Load temporal data\nmovie = load_movie()  # Shape: (100, 512, 512)\n\n# 2. Estimate parameters\nparams = compute_conversion_gain(movie)\nprint(f\"Estimated parameters:\")\nprint(f\"  Conversion gain: {params['sensitivity']:.3f} ADU/photon\")\nprint(f\"  Zero level: {params['zero_level']:.1f} ADU\")\n\n# 3. Validate fit quality\nr2_score = params['model'].score(\n    params['variance'].ravel().reshape(-1, 1),\n    np.mean(movie, axis=0).ravel()\n)\nprint(f\"  Fit quality (R\u00b2): {r2_score:.3f}\")\n\n# 4. Create codec with estimated parameters\ncodec = AnscombeTransformV3(\n    zero_level=params['zero_level'],\n    conversion_gain=params['sensitivity']\n)\n\n# 5. Create Zarr array\narr = zarr.create(\n    shape=movie.shape,\n    chunks=(10, 512, 512),\n    dtype='int16',\n    filters=[codec],\n    zarr_format=3\n)\n\n# 6. Compress data\narr[:] = movie\nprint(f\"Compression successful!\")\n</code></pre>"},{"location":"user-guide/parameter-estimation/#next-steps","title":"Next Steps","text":"<ul> <li>Zarr V2 Integration</li> <li>Zarr V3 Integration</li> <li>API Reference: estimate module</li> </ul>"},{"location":"user-guide/zarr-v2/","title":"Zarr V2 Integration","text":"<p>This guide covers using the Anscombe Transform codec with Zarr V2.</p>"},{"location":"user-guide/zarr-v2/#basic-usage","title":"Basic Usage","text":"<pre><code>import zarr\nimport numpy as np\nfrom anscombe_transform import AnscombeTransformV2\n\n# Create data\ndata = np.random.poisson(lam=50, size=(100, 512, 512)).astype('int16')\n\n# Create Zarr V2 array with Anscombe codec as compressor\narr = zarr.open_array(\n    'data.zarr',\n    mode='w',\n    shape=data.shape,\n    chunks=(10, 512, 512),\n    dtype='int16',\n    compressor=AnscombeTransformV2(\n        zero_level=100,\n        conversion_gain=2.5\n    )\n)\n\n# Write and read\narr[:] = data\nrecovered = arr[:]\n</code></pre>"},{"location":"user-guide/zarr-v2/#using-with-additional-compression","title":"Using with Additional Compression","text":"<p>In Zarr V2, the Anscombe codec can be combined with other compressors by nesting them:</p> <pre><code>from numcodecs import Blosc\nfrom anscombe_transform import AnscombeTransformV2\n\n# Note: Zarr V2 doesn't support filter chains natively\n# The Anscombe codec must be the primary compressor\ncompressor = AnscombeTransformV2(\n    zero_level=100,\n    conversion_gain=2.5,\n    encoded_dtype='uint8'\n)\n\narr = zarr.open_array(\n    'compressed.zarr',\n    mode='w',\n    shape=(100, 512, 512),\n    chunks=(10, 512, 512),\n    dtype='int16',\n    compressor=compressor\n)\n</code></pre> <p>Limitation</p> <p>Zarr V2 doesn't support filter chains like V3 does. The Anscombe codec serves as both the transform and the compressor. For better compression with additional algorithms, consider upgrading to Zarr V3.</p>"},{"location":"user-guide/zarr-v2/#codec-parameters","title":"Codec Parameters","text":""},{"location":"user-guide/zarr-v2/#required-parameters","title":"Required Parameters","text":"<ul> <li><code>zero_level</code> (float): Baseline signal with no photons</li> <li><code>conversion_gain</code> (float): Signal units per photon (also called <code>photon_sensitivity</code>)</li> </ul>"},{"location":"user-guide/zarr-v2/#optional-parameters","title":"Optional Parameters","text":"<ul> <li><code>encoded_dtype</code> (str or dtype): Data type for encoded values, default: <code>'uint8'</code></li> <li>Use <code>'uint8'</code> for maximum compression (0-255 range)</li> <li>Use <code>'uint16'</code> for higher dynamic range</li> <li><code>decoded_dtype</code> (str or dtype): Data type for decoded output, default: inferred from input</li> </ul>"},{"location":"user-guide/zarr-v2/#codec-registration","title":"Codec Registration","text":"<p>The codec is automatically registered when you import it:</p> <pre><code>from anscombe_transform import AnscombeTransformV2\nimport numcodecs\n\n# The codec is now registered\ncodec = numcodecs.get_codec({'id': 'anscombe-v1', 'zero_level': 100, 'conversion_gain': 2.5})\n</code></pre>"},{"location":"user-guide/zarr-v2/#serialization","title":"Serialization","text":"<p>The codec can be serialized to/from JSON:</p> <pre><code>from anscombe_transform import AnscombeTransformV2\n\n# Create codec\ncodec = AnscombeTransformV2(zero_level=100, conversion_gain=2.5)\n\n# Serialize to dict\nconfig = codec.get_config()\nprint(config)\n# {'id': 'anscombe-v1', 'zero_level': 100, 'conversion_gain': 2.5, ...}\n\n# Deserialize from dict\ncodec2 = AnscombeTransformV2.from_config(config)\n</code></pre> <p>This is useful for: - Storing codec configuration in metadata - Sharing compression settings across systems - Programmatic codec creation</p>"},{"location":"user-guide/zarr-v2/#working-with-existing-arrays","title":"Working with Existing Arrays","text":""},{"location":"user-guide/zarr-v2/#reading-compressed-data","title":"Reading Compressed Data","text":"<p>If data was compressed with the Anscombe codec:</p> <pre><code>import zarr\nfrom anscombe_transform import AnscombeTransformV2\n\n# Open existing array (codec info is stored in .zarray metadata)\narr = zarr.open_array('data.zarr', mode='r')\n\n# Read data (automatically decompressed)\ndata = arr[:]\n</code></pre>"},{"location":"user-guide/zarr-v2/#inspecting-codec-configuration","title":"Inspecting Codec Configuration","text":"<pre><code>import zarr\nimport json\n\n# Read .zarray metadata\nwith open('data.zarr/.zarray', 'r') as f:\n    metadata = json.load(f)\n\nprint(metadata['compressor'])\n# {'id': 'anscombe-v1', 'zero_level': 100, 'conversion_gain': 2.5, ...}\n</code></pre>"},{"location":"user-guide/zarr-v2/#migration-to-zarr-v3","title":"Migration to Zarr V3","text":"<p>To migrate data from V2 to V3:</p> <pre><code>import zarr\nfrom anscombe_transform import AnscombeTransformV2, AnscombeTransformV3\n\n# Open V2 array\nv2_arr = zarr.open_array('data_v2.zarr', mode='r')\n\n# Get codec config\nv2_config = v2_arr.compressor.get_config()\n\n# Create V3 array with equivalent codec\nv3_arr = zarr.create(\n    shape=v2_arr.shape,\n    chunks=v2_arr.chunks,\n    dtype=v2_arr.dtype,\n    filters=[AnscombeTransformV3(\n        zero_level=v2_config['zero_level'],\n        conversion_gain=v2_config['conversion_gain']\n    )],\n    zarr_format=3\n)\n\n# Copy data\nv3_arr[:] = v2_arr[:]\n</code></pre>"},{"location":"user-guide/zarr-v2/#api-reference","title":"API Reference","text":"<p>See the Codec API Reference for detailed documentation of all parameters and methods.</p>"},{"location":"user-guide/zarr-v2/#next-steps","title":"Next Steps","text":"<ul> <li>Zarr V3 Integration - Learn about the improved V3 interface</li> <li>Parameter Estimation - Estimate codec parameters from data</li> <li>Examples - See complete examples</li> </ul>"},{"location":"user-guide/zarr-v3/","title":"Zarr V3 Integration","text":"<p>This guide covers using the Anscombe Transform codec with Zarr V3, which provides improved performance and flexibility.</p>"},{"location":"user-guide/zarr-v3/#basic-usage","title":"Basic Usage","text":"<pre><code>import zarr\nimport numpy as np\nfrom anscombe_transform import AnscombeTransformV3\n\n# Create data\ndata = np.random.poisson(lam=50, size=(100, 512, 512)).astype('int16')\n\n# Create Zarr V3 array with Anscombe codec as a filter\nstore = zarr.storage.MemoryStore()\narr = zarr.create(\n    store=store,\n    shape=data.shape,\n    chunks=(10, 512, 512),\n    dtype='int16',\n    filters=[AnscombeTransformV3(\n        zero_level=100,\n        conversion_gain=2.5\n    )],\n    zarr_format=3\n)\n\n# Write and read\narr[:] = data\nrecovered = arr[:]\n</code></pre>"},{"location":"user-guide/zarr-v3/#filter-chains","title":"Filter Chains","text":"<p>Zarr V3 supports filter chains, allowing you to combine the Anscombe transform with other compression algorithms:</p> <pre><code>import zarr\nfrom anscombe_transform import AnscombeTransformV3\n\n# Use Anscombe as a filter with Blosc compression\narr = zarr.create(\n    shape=(100, 512, 512),\n    chunks=(10, 512, 512),\n    dtype='int16',\n    filters=[\n        AnscombeTransformV3(zero_level=100, conversion_gain=2.5)\n    ],\n    compressor={\n        'id': 'blosc',\n        'cname': 'zstd',\n        'clevel': 5,\n        'shuffle': 'bitshuffle'\n    },\n    zarr_format=3\n)\n</code></pre> <p>The processing pipeline is: 1. Original data (int16) 2. Anscombe filter \u2192 transformed data (uint8) 3. Blosc compressor \u2192 compressed bytes 4. Storage</p>"},{"location":"user-guide/zarr-v3/#recommended-compressors","title":"Recommended Compressors","text":"<p>Different compressors work well with the Anscombe-transformed data:</p>"},{"location":"user-guide/zarr-v3/#blosc-with-zstd-best-overall","title":"Blosc with Zstd (Best Overall)","text":"<pre><code>filters = [AnscombeTransformV3(zero_level=100, conversion_gain=2.5)]\ncompressor = {\n    'id': 'blosc',\n    'cname': 'zstd',      # Excellent compression + speed\n    'clevel': 5,          # Compression level (1-9)\n    'shuffle': 'bitshuffle'\n}\n</code></pre>"},{"location":"user-guide/zarr-v3/#blosc-with-lz4-fastest","title":"Blosc with LZ4 (Fastest)","text":"<pre><code>compressor = {\n    'id': 'blosc',\n    'cname': 'lz4',       # Fastest decompression\n    'clevel': 3,\n    'shuffle': 'bitshuffle'\n}\n</code></pre>"},{"location":"user-guide/zarr-v3/#blosc-with-zlib-maximum-compression","title":"Blosc with Zlib (Maximum Compression)","text":"<pre><code>compressor = {\n    'id': 'blosc',\n    'cname': 'zlib',      # Best compression ratio\n    'clevel': 9,\n    'shuffle': 'bitshuffle'\n}\n</code></pre>"},{"location":"user-guide/zarr-v3/#codec-parameters","title":"Codec Parameters","text":""},{"location":"user-guide/zarr-v3/#required-parameters","title":"Required Parameters","text":"<ul> <li><code>zero_level</code> (float): Baseline signal with no photons</li> <li><code>conversion_gain</code> (float): Signal units per photon</li> </ul>"},{"location":"user-guide/zarr-v3/#optional-parameters","title":"Optional Parameters","text":"<ul> <li><code>encoded_dtype</code> (str or dtype): Data type for encoded values, default: <code>'uint8'</code></li> <li><code>decoded_dtype</code> (str or dtype): Data type for decoded output, default: inferred</li> <li><code>beta</code> (float): Quantization step size in noise standard deviations, default: <code>0.5</code></li> </ul>"},{"location":"user-guide/zarr-v3/#advanced-beta-parameter","title":"Advanced: Beta Parameter","text":"<p>The <code>beta</code> parameter controls the quantization precision:</p> <pre><code># Finer quantization (more levels, better accuracy, less compression)\ncodec_fine = AnscombeTransformV3(\n    zero_level=100,\n    conversion_gain=2.5,\n    beta=0.25  # Half the default step size\n)\n\n# Coarser quantization (fewer levels, more compression, lower accuracy)\ncodec_coarse = AnscombeTransformV3(\n    zero_level=100,\n    conversion_gain=2.5,\n    beta=1.0  # Double the default step size\n)\n</code></pre> <p>Default <code>beta=0.5</code> means each quantization level represents 0.5 standard deviations of noise, which is a good balance for most applications.</p>"},{"location":"user-guide/zarr-v3/#codec-registration","title":"Codec Registration","text":"<p>The codec is automatically registered with Zarr V3:</p> <pre><code>from anscombe_transform import AnscombeTransformV3\nimport zarr\n\n# Check if registered\nprint('anscombe-v1' in zarr.codecs.registry.get_codec_class('anscombe-v1'))\n</code></pre>"},{"location":"user-guide/zarr-v3/#serialization-and-metadata","title":"Serialization and Metadata","text":""},{"location":"user-guide/zarr-v3/#codec-configuration","title":"Codec Configuration","text":"<p>The codec configuration is stored in the array metadata:</p> <pre><code>import zarr\nfrom anscombe_transform import AnscombeTransformV3\n\n# Create array\narr = zarr.create(\n    shape=(100, 512, 512),\n    dtype='int16',\n    filters=[AnscombeTransformV3(zero_level=100, conversion_gain=2.5)],\n    zarr_format=3\n)\n\n# Access metadata\nprint(arr.metadata)\n</code></pre>"},{"location":"user-guide/zarr-v3/#json-serialization","title":"JSON Serialization","text":"<pre><code>from anscombe_transform import AnscombeTransformV3\n\ncodec = AnscombeTransformV3(zero_level=100, conversion_gain=2.5)\n\n# Convert to dict\nconfig = codec.to_dict()\nprint(config)\n# {'name': 'anscombe-v1', 'configuration': {'zero_level': 100, ...}}\n\n# Reconstruct from dict\ncodec2 = AnscombeTransformV3.from_dict(config)\n</code></pre>"},{"location":"user-guide/zarr-v3/#performance-optimization","title":"Performance Optimization","text":""},{"location":"user-guide/zarr-v3/#chunk-size-selection","title":"Chunk Size Selection","text":"<p>Choose chunk sizes that balance compression and access patterns:</p> <pre><code># For sequential access (e.g., video playback)\nchunks = (10, 512, 512)  # 10 frames at a time\n\n# For random time-point access\nchunks = (1, 512, 512)   # Single frames\n\n# For spatial crops across time\nchunks = (100, 128, 128) # Smaller spatial regions, all time points\n</code></pre>"},{"location":"user-guide/zarr-v3/#parallel-processing","title":"Parallel Processing","text":"<p>Zarr V3 supports parallel chunk processing:</p> <pre><code>import zarr\nfrom concurrent.futures import ThreadPoolExecutor\n\narr = zarr.open_array('data.zarr', mode='r')\n\n# Read chunks in parallel\nwith ThreadPoolExecutor(max_workers=4) as executor:\n    futures = []\n    for i in range(0, arr.shape[0], 10):\n        future = executor.submit(lambda i=i: arr[i:i+10])\n        futures.append(future)\n\n    results = [f.result() for f in futures]\n</code></pre>"},{"location":"user-guide/zarr-v3/#working-with-different-storage-backends","title":"Working with Different Storage Backends","text":""},{"location":"user-guide/zarr-v3/#local-filesystem","title":"Local Filesystem","text":"<pre><code>import zarr\nfrom anscombe_transform import AnscombeTransformV3\n\nstore = zarr.storage.LocalStore('data.zarr')\narr = zarr.create(\n    store=store,\n    shape=(100, 512, 512),\n    filters=[AnscombeTransformV3(zero_level=100, conversion_gain=2.5)],\n    zarr_format=3\n)\n</code></pre>"},{"location":"user-guide/zarr-v3/#in-memory","title":"In-Memory","text":"<pre><code>store = zarr.storage.MemoryStore()\narr = zarr.create(\n    store=store,\n    shape=(100, 512, 512),\n    filters=[AnscombeTransformV3(zero_level=100, conversion_gain=2.5)],\n    zarr_format=3\n)\n</code></pre>"},{"location":"user-guide/zarr-v3/#remote-storage-s3-gcs","title":"Remote Storage (S3, GCS)","text":"<pre><code>import zarr\nfrom anscombe_transform import AnscombeTransformV3\n\n# Requires fsspec and s3fs/gcsfs\nstore = zarr.storage.RemoteStore('s3://bucket/data.zarr')\narr = zarr.create(\n    store=store,\n    shape=(100, 512, 512),\n    filters=[AnscombeTransformV3(zero_level=100, conversion_gain=2.5)],\n    zarr_format=3\n)\n</code></pre>"},{"location":"user-guide/zarr-v3/#api-reference","title":"API Reference","text":"<p>See the Codec API Reference for detailed documentation.</p>"},{"location":"user-guide/zarr-v3/#next-steps","title":"Next Steps","text":"<ul> <li>Parameter Estimation - Estimate codec parameters</li> <li>Examples - Complete workflow examples</li> <li>Zarr V2 Integration - If you need V2 compatibility</li> </ul>"}]}